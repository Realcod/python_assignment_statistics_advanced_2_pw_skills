{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#1  Define the z-statistic and explain its relationship to the standard normal distribution. How is the z-statistic used in hypothesis testing?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\nThe z-statistic (or z-score) is a statistical measure that describes how many standard deviations a data point is from the mean of a data set\nRelationship to the Standard Normal Distribution:\nThe z-statistic is directly related to the standard normal distribution, which is a special type of normal distribution with a mean of 0 and a standard deviation of 1. When a dataset follows a normal distribution, the z-statistic allows us to convert any data point into a standardized form that fits within this standard normal distribution.\n\nIn a standard normal distribution:\n\nThe mean is 0.\nThe standard deviation is 1.\n68% of values fall within 1 standard deviation (z = ¬±1).\n95% of values fall within 2 standard deviations (z = ¬±2).\n99.7% of values fall within 3 standard deviations (z = ¬±3).\nWhen we calculate the z-statistic, we essentially \"standardize\" the data, so we can use the properties of the standard normal distribution to make \nprobability-related decisions.\n\nIn hypothesis testing, the z-statistic is used to determine whether a sample mean is significantly different from a known or hypothesized population mean. \n\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#2  What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value is very small (e.g., 0.01)?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\nA p-value (probability value) is the probability of observing a test statistic as extreme as, or more extreme than, the one observed in your sample data, assuming \nthat the null hypothesis  is true. It quantifies the evidence against the null hypothesis.\n\nIn hypothesis testing, the p-value is used to decide whether to reject or fail to reject the null hypothesis. \n\nIf the p-value is very small, such as 0.01, it means that the observed data is highly unlikely to have occurred under the assumption that the null hypothesis is true.\n\nA p-value of 0.01 indicates that there is only a 1% probability that the observed test statistic (or something more extreme) would occur if the null hypothesis were true.\nIn such cases, since the p-value is less than the commonly used significance level of 0.05, you would reject the null hypothesis.\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#3 Compare and contrast the binomial and Bernoulli distributions. ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\nThe Bernoulli distribution models a single trial or experiment that has two possible outcomes:\n\nSuccess with probability p\nFailure with probability 1-p\n\nIt is named after the Swiss mathematician Jacob Bernoulli.\n\nKey Features of the Bernoulli Distribution:\nExperiment: A single trial.\n\nOutcomes: Two outcomes (typically coded as 1 for success and 0 for failure).\n\nUse Cases:\nThe Bernoulli distribution is used when we are only interested in the outcome of one trial.\nExample: Tossing a coin once, where heads = success (1) and tails = failure (0).\n\n2. Binomial Distribution:\nThe binomial distribution is an extension of the Bernoulli distribution to multiple independent and identical trials.\n\nIt models the number of successes in a fixed number of ùëõn independent Bernoulli trials, each with the same probability of success ùëù.\nKey Features of the Binomial Distribution:\nExperiment: n independent Bernoulli trials (repeated experiments).\nOutcomes: Two outcomes per trial (success or failure).\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#4  Under what conditions is the binomial distribution used, and how does it relate to the Bernoulli distribution?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\nThe binomial distribution is used under the following conditions, often referred to as the BINS criteria:\n\nBinary Outcomes (B): Each trial has only two possible outcomes, often referred to as \"success\" and \"failure.\" For example, \nflipping a coin results in either heads (success) or tails (failure).\n\nIndependent Trials (I): The outcome of each trial is independent of the others. That means the result of one trial does not influence the result of any other trial.\nFixed Number of Trials (N): The number of trials, ùëõ is fixed in advance. For example, you might flip a coin 10 times\n\nSame Probability of Success (S): Each trial has the same probability of success, denoted by p. This probability does not change throughout the trials.\n\nRelationship Between Binomial and Bernoulli Distributions:\nThe binomial distribution is an extension of the Bernoulli distribution. The Bernoulli distribution describes the outcome of a single \ntrial with two possible outcomes (success or failure), whereas the binomial distribution describes the number of successes in a \nfixed number of independent trials,  where each trial is a Bernoulli trial.\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#5 What are the key properties of the Poisson distribution, and when is it appropriate to use this distribution?\n\"\"\"\nThe Poisson distribution is a discrete probability distribution that describes the probability of a given number of events occurring within a fixed interval of time, space, or any other continuum, provided that the events occur with a known constant rate and are independent of each other.\n\nHere are its key properties:\n\nDiscrete Distribution:\n\nThe Poisson distribution applies to a discrete random variable, which means it describes the probability of a specific number of events \nhappening (e.g., 0, 1, 2, 3 events, etc.).\n\nMemorylessness:\n\nThe Poisson distribution is often used to describe events that occur randomly and independently over time. One key feature of a Poisson process is that the waiting time until the next event is independent of when the last event occurred (though the Poisson distribution itself does not directly model waiting times; that‚Äôs handled by the exponential distribution).\nSkewness:\nThe Poisson distribution is generally right-skewed, especially when Œª is small. As Œª increases, the distribution becomes more symmetric and\napproximates a normal distribution.\n\nEvents are Rare: The Poisson distribution is typically used to model rare or infrequent events that occur randomly over time or space.\n\nWhen Is It Appropriate to Use the Poisson Distribution?\nThe Poisson distribution is appropriate to use under the following conditions:\n\nEvents Are Independent: The occurrence of one event does not affect the occurrence of another event. For example, \nif you are counting how many cars pass through a tollbooth in an hour, the arrival of one car should not affect the arrival of another.\n\nFixed Interval: The Poisson distribution applies to a fixed interval of time, space, area, volume, etc. \nThis could be a fixed amount of time (e.g., per hour), area (e.g., per square kilometer), or another measurable unit (e.g., number of typos per page).\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#6  Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does a PDF differ from a probability mass function (PMF)?\n\"\"\"\nProbability Distribution:\nA probability distribution is a function or rule that describes the likelihood of different outcomes in a random experiment. It gives us the probabilities associated with the possible values of a random variable, whether the variable is discrete or continuous. There are two types of probability distributions \nbased on the nature of the random variable:\n\nDiscrete Probability Distribution: Describes the probability for discrete random variables (i.e., variables that take on distinct, separate values). For example, the number of heads in a series of coin flips is a discrete random variable.\n\nContinuous Probability Distribution: Describes the probability for continuous random variables (i.e., variables that can take any value within a certain range). For example, the height of people is a \ncontinuous random variable.\n\nProbability Density Function (PDF):\nA probability density function (PDF) is used to describe the probability distribution of a continuous random variable. \nThe PDF gives the relative likelihood that the random variable takes on a particular value within its range.\n\nThe PDF is a non-negative function, and it integrates to 1 over the entire range of possible values because the total probability of all \npossible outcomes must equal 1.\n\nProbability Mass Function (PMF):\nA probability mass function (PMF) is used for discrete random variables. It assigns probabilities to the specific values that a discrete \nrandom variable can take.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#7 Explain the Central Limit Theorem (CLT) with example.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\nThe Central Limit Theorem (CLT) is one of the most fundamental theorems in statistics. It states that, regardless of the original distribution of a population, the sampling distribution of the sample mean will approach a normal distribution (bell-shaped curve) as the sample size becomes large enough, given that the samples are independent and \nidentically distributed (i.i.d.).\nMore specifically:\n\nIf you take many random samples of size n from any population (whether the population distribution is normal or not) and\ncompute the mean of each sample, the distribution of those sample means will tend to follow a normal distribution as ùëõ increases.\n\nNow, consider taking random samples of 50 students at a time and calculating the average test score for each sample.\n\nThe original population distribution of test scores is not normal. It is right-skewed because a few students scored much lower than the others.\nHowever, if you repeatedly take random samples of size n=50  and for eac sample, you calculate the average test score (i.e., the sample mean), the distribution of these sample means will become approximately normal, even though the \nunderlying population distribution is not normal.\n\nAs you increase the sample size the distribution of the sample means will become more closely approximated by a normal distribution.\n\"\"\"\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#8 Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be applied instead?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\nZ-Scores:\nA z-score measures how many standard deviations a data point is from the population mean. It assumes that you know the population standard deviation \nùúé and that the underlying distribution is normal.\n\nT-Scores:\nA t-score is used in place of the z-score when the population standard deviation \nœÉ is unknown, and you have a small sample size (typically ùëõ <30). The t-score compensates for the extra uncertainty in estimating the population \nstandard deviation from the sample.\n\nWhen to Use Z-Scores:\nLarge sample sizes (typically n>30). When the population standard deviation \nùúé is known.\nWhen the population is normally distributed or the sample size is large enough for the Central Limit Theorem to apply,\nmaking the sampling distribution of the sample mean approximately normal.\n\nWhen to Use T-Scores:\nSmall sample sizes (typically n<30).\nWhen the population standard deviation œÉ is unknown (which is often the case in real-world situations).\nWhen the population distribution is not normal, and the sample size is small, requiring the t-distribution's heavier tails to account for \nincreased variability.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#9 : Given a sample mean of 105, a population mean of 100, a standard deviation of 15, and a sample\n# size of 25, calculate the z-score and p-value. Based on a significance level of 0.05, do you reject or fail to\n#reject the null hypothesis?\n#Task: Write Python code to calculate the z-score and p-value for the given data.\n#Objective: Apply the formula for the z-score and interpret the p-value for hypothesis testing.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import scipy.stats as stats\n\n# Given data\nsample_mean = 105\npopulation_mean = 100\nstd_dev = 15\nsample_size = 25\n\n# Calculate the z-score\nz_score = (sample_mean - population_mean) / (std_dev / (sample_size ** 0.5))\n\n# Calculate the p-value (two-tailed test)\np_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n\n# Significance level\nalpha = 0.05\n\n# Decision: reject or fail to reject the null hypothesis\nreject_null = p_value < alpha\n\nprint(f\"Z-Score: {z_score}\")\nprint(f\"P-Value: {p_value}\")\nprint(f\"Reject Null Hypothesis: {reject_null}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Z-Score: 1.6666666666666667\nP-Value: 0.09558070454562939\nReject Null Hypothesis: False\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\nConclusion:\nSince the p-value (0.096) is greater than the significance level  Œ±=0.05, we fail to reject the null hypothesis.\nThis means there is not enough evidence to suggest that the sample mean is significantly different from the population mean at the 0.05 \nsignificance level. ‚Äã\n\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#10 : Simulate a binomial distribution with 10 trials and a probability of success of 0.6 using Python.\n#Generate 1,000 samples and plot the distribution. What is the expected mean and variance?\n#Task: Use Python to generate the data, plot the distribution, and calculate the mean and variance.\n#Objective: Understand the properties of a binomial distribution and verify them through simulation.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\"\"\"\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}